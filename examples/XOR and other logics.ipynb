{
 "metadata": {
  "name": "",
  "signature": "sha256:7d66194cc9ca375343f318a3c8218c60cdb93551e37862f0eb665ada3c58c9f7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data set\n",
      "\n",
      "Let's define the classical XOR data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# Using floats (doubles) are important later\n",
      "xor = np.array([[0, 0, 0],\n",
      "                [0, 1, 1],\n",
      "                [1, 0, 1],\n",
      "                [1, 1, 0]], dtype=float)\n",
      "print(xor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.]\n",
        " [ 0.  1.  1.]\n",
        " [ 1.  0.  1.]\n",
        " [ 1.  1.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The input is the first two columns, and the target is the last column. Note that the shape of the data is important."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xor_in = xor[:, :2]\n",
      "xor_target = xor[:, -1:]\n",
      "\n",
      "print(xor_in)\n",
      "print(xor_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.]\n",
        " [ 0.  1.]\n",
        " [ 1.  0.]\n",
        " [ 1.  1.]]\n",
        "[[ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create a suitable neural network\n",
      "\n",
      "There are different networks depending on the training method one wishes to use. GeneticNetwork uses a\n",
      "genetic algorithm as is the most flexible when it comes to error functions. RpropNetwork uses the iRprop+\n",
      "method and is the fastest but requires a differentiable error function.\n",
      "\n",
      "Since I will use the mean square error, I'll select Rprop.\n",
      "\n",
      "All types share the same constructor signature, taking the number of input, hidden and output neurons respectively:\n",
      "\n",
      "    net = NETWORKTYPE(input_count, hidden_count, output_count)\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ann import rpropnetwork\n",
      "\n",
      "# Create a network matching the data, with a couple of hidden neurons\n",
      "net = rpropnetwork(xor_in.shape[1], 4, xor_target.shape[1])\n",
      "\n",
      "# Total amount of neurons (including the bias neuron, of which there is only one)\n",
      "neuron_count = net.input_count + net.hidden_count + net.output_count + 1\n",
      "# All zero connections at first\n",
      "print(\"Default connections\")\n",
      "print(net.connections.reshape((neuron_count, neuron_count)))\n",
      "# All weights are zero too\n",
      "print(\"\\nDefault weights\")\n",
      "print(net.weights.reshape((neuron_count, neuron_count)))\n",
      "\n",
      "print(\"\\nDefault activation functions are linear ({})\".format(net.LINEAR))\n",
      "print(net.activation_functions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Default connections\n",
        "[[0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0]]\n",
        "\n",
        "Default weights\n",
        "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
        "\n",
        "Default activation functions are linear (0)\n",
        "[0 0 0 0 0 0 0 0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Connecting the network\n",
      "\n",
      "By default, the network has no connections between neurons. You are able to \n",
      "set both the weights and connections to values of your liking but a convenience\n",
      "method is supplied for creating feedforward networks.\n",
      "\n",
      "The connections and weights are defined as NxN matrices of ints and doubles\n",
      "respectively. Activation functions can also be set on the individual neuron\n",
      "level if desired using the N-length vector activation_functions. To do interesting\n",
      "stuff, make sure hidden neurons use either tanh or logsig. These are set for you\n",
      "by the connect_feedforward method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ann import connect_feedforward\n",
      "# Connect in a single hidden layer (default) with logsig functions on both\n",
      "# hidden and outputs (also default)\n",
      "connect_feedforward(net)\n",
      "\n",
      "print(\"\\n\\nFeedforward connections\")\n",
      "print(net.connections.reshape((neuron_count, neuron_count)))\n",
      "print(\"\\nWeights have been randomized and normalized to suitable ranges\")\n",
      "print(net.weights.reshape((neuron_count, neuron_count)))\n",
      "\n",
      "print(\"\\nActivation functions are now changed to logsig ({})\".format(net.LOGSIG))\n",
      "print(net.activation_functions)\n",
      "print(\"\\nInputs and Bias have no activation functions, or connections to other neurons\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Feedforward connections\n",
        "[[0 0 1 0 0 0 0 0]\n",
        " [0 0 1 0 0 0 0 0]\n",
        " [0 0 1 0 0 0 0 0]\n",
        " [1 1 1 0 0 0 0 0]\n",
        " [1 1 1 0 0 0 0 0]\n",
        " [1 1 1 0 0 0 0 0]\n",
        " [1 1 1 0 0 0 0 0]\n",
        " [0 0 1 1 1 1 1 0]]\n",
        "\n",
        "Weights have been randomized and normalized to suitable ranges\n",
        "[[  2.34390302e-01   1.48599413e-01  -1.27586706e+00   6.63885407e-01\n",
        "   -9.57722056e-01  -5.26258883e-01  -1.17054438e+00   2.05176069e+00]\n",
        " [  2.10684640e+00  -1.20992258e+00  -7.87622229e-01   2.65956108e-01\n",
        "    3.79281410e-01   1.96161791e+00   1.38639707e-02  -3.90191710e-01]\n",
        " [  6.94340032e-01   5.64623053e-01   3.62250147e-01  -2.88287230e-01\n",
        "    1.26778449e+00   9.91237329e-01  -7.30969473e-01   5.56962499e-01]\n",
        " [  4.56087358e-01  -5.12488290e-01   3.14243522e-02   7.97542099e-01\n",
        "    4.44247884e-01   2.58191511e-01   2.70880575e-01  -1.16556508e+00]\n",
        " [ -9.70020918e-01   1.03284643e-03  -2.89462361e-02   1.16868670e+00\n",
        "    8.80225813e-01  -5.49047973e-02   1.33169280e+00   4.89071263e-02]\n",
        " [ -1.73598733e-01   2.02388658e-01  -6.24012608e-01   7.82505067e-02\n",
        "   -1.22489562e-01   1.68608653e-01   1.21853670e+00   4.33320502e-02]\n",
        " [ -2.98344967e-01  -2.50058977e-01  -4.51596056e-01   6.83487914e-01\n",
        "   -8.25172901e-01   6.76609952e-01   1.25793199e+00   1.63677667e+00]\n",
        " [  7.29609653e-01  -4.26469333e-01  -3.48338603e-01   3.84692714e-01\n",
        "    4.74986327e-01  -4.06394526e-02  -9.96815061e-02   6.60039848e-01]]\n",
        "\n",
        "Activation functions are now changed to logsig (1)\n",
        "[0 0 0 1 1 1 1 1]\n",
        "\n",
        "Inputs and Bias have no activation functions, or connections to other neurons\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training the network\n",
      "\n",
      "All networks have the same training method signature:\n",
      "\n",
      "    net.learn(inputdata, targetdata)\n",
      "    \n",
      "Each method naturally has a couple of different parameters you can tweak. These are set as\n",
      "variables on the networks themselves. As an example, let's see what some default Rprop values are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Error function:\", net.error_function, net.ERROR_MSE)\n",
      "\n",
      "print(\"Max training iterations:\", net.maxEpochs)\n",
      "print(\"Max error accepted for early stopping:\", net.maxError)\n",
      "print(\"Min change in error to consider training to be done:\", net.minErrorFrac)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error function: 0 0\n",
        "Max training iterations: 1000\n",
        "Max error accepted for early stopping: 0.0001\n",
        "Min change in error to consider training to be done: 0.01\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Actually train it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.learn(xor_in, xor_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's see what the output and error is\n",
      "\n",
      "To ask the network to predict something, give it a row from the input data:\n",
      "\n",
      "    net.output(xrow)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outputs = []\n",
      "for x in xor_in:\n",
      "    y = net.output(x)\n",
      "    \n",
      "    print(\"{:.0f} X {:.0f} = {:.1f}\".format(x[0], x[1], y[0]))\n",
      "    outputs.append(y)\n",
      "    \n",
      "outputs = np.array(outputs)\n",
      "\n",
      "# Note that y is an array\n",
      "y.shape == (net.output_count,)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 X 0 = 0.0\n",
        "0 X 1 = 1.0\n",
        "1 X 0 = 1.0\n",
        "1 X 1 = 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mean square error is defined as:\n",
      "\n",
      "$$ e = \\frac{1}{N} \\sum_i^N (\\tau_i - y_i)^2 $$\n",
      "\n",
      "The package however divides by two, and neglects the N-term, to make the\n",
      "differential $(\\tau_i - y_i)$ instead of:\n",
      "\n",
      "$$ \\frac{de}{dy_i} = \\frac{2}{N}(\\tau_i - y_i) $$\n",
      "\n",
      "Just to remove some calculations from the process. It has no impact on training."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Mean square error then\n",
      "e = np.sum((xor_target - outputs)**2) / len(xor_target)\n",
      "print(\"MSE: {:.6f}\".format(e))\n",
      "\n",
      "# Can also ask the package to calculate it for us\n",
      "from ann import get_error\n",
      "\n",
      "e = get_error(net.ERROR_MSE, xor_target, outputs)\n",
      "\n",
      "# This is not summed for us as it is used in training piece by piece\n",
      "print(\"MSE: {:.6f}\".format(2 * e.sum()/len(xor_target)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MSE: 0.000030\n",
        "MSE: 0.000030\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}